{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import useful packages\n",
    "import numpy as np\n",
    "import sklearn\n",
    "import sklearn.tree\n",
    "import sklearn.metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define functions and common variables\n",
    "def create_output_file(y_actual, y_predicted, labels, filename):\n",
    "    '''\n",
    "    Function for creating the ouput file as specified in the assignment instructions:\n",
    "    a) instance number and predicted label (number)\n",
    "    b) Confusion matrix\n",
    "    c) Precision, recall and f1-measure of each class\n",
    "    d) Accuracy, macro-average f1 and weighted-average f1 score of the model\n",
    "\n",
    "    y_actual: numpy array of shape (N,) containing the actual class of each test instance\n",
    "    y_predicted: numpy array of shape (N,) containing the class of each test instance predicted by the model\n",
    "    labels: 1D numpy array containing the class labels of the dataset\n",
    "    filename: name of the output (.csv) file\n",
    "    '''\n",
    "\n",
    "    # Open file\n",
    "    output = open('A1-Output/' + filename + '.csv', 'w')\n",
    "\n",
    "    # a) Write y values of test data\n",
    "    output.write('instance,prediction\\n')\n",
    "    for i in range(y_predicted.shape[0]):\n",
    "        output.write(str(i+1) + ',' + str(y_predicted[i]) + '\\n')\n",
    "\n",
    "    output.write('\\n')\n",
    "\n",
    "    # b) Plot confusion matrix\n",
    "    output.write('confusion matrix\\n')\n",
    "    confusion_matrix = sklearn.metrics.confusion_matrix(y_actual, y_predicted)\n",
    "    (m, n) = confusion_matrix.shape\n",
    "    for i in range(m):\n",
    "        for j in range(n):\n",
    "            if j < n-1:\n",
    "                output.write(str(confusion_matrix[i,j]) + ',')\n",
    "            else:\n",
    "                output.write(str(confusion_matrix[i,j]))\n",
    "        output.write('\\n')\n",
    "\n",
    "    output.write('\\n')\n",
    "\n",
    "    # c) Write precision, recall and f1-measure of each class (rounded to 2 decimals)\n",
    "    output.write('precision,recall,f1-measure\\n')\n",
    "    precision = sklearn.metrics.precision_score(y_actual, y_predicted, average=None)\n",
    "    recall = sklearn.metrics.recall_score(y_actual, y_predicted, average=None)\n",
    "    f1 = sklearn.metrics.f1_score(y_actual, y_predicted, average=None)\n",
    "\n",
    "    for i in range(labels.shape[0]):\n",
    "        #output.write(str(precision[i]) + ',' + str(recall[i]) + ',' + str(f1[i]) + '\\n')\n",
    "        output.write('{:.2f},{:.2f},{:.2f}\\n'.format(precision[i], recall[i], f1[i]))\n",
    "\n",
    "    output.write('\\n')\n",
    "\n",
    "    # Write accuracy, macro-average f1 and weighted-average f1 of the model (rounded to 2 decimals)\n",
    "    output.write('accuracy,macro-average f-1,weighted-average f1\\n') \n",
    "    accuracy = sklearn.metrics.accuracy_score(y_actual, y_predicted)\n",
    "    macro_avg_f1 = sklearn.metrics.f1_score(y_actual, y_predicted, average='macro')\n",
    "    weighted_avg_f1 = sklearn.metrics.f1_score(y_actual, y_predicted, average='weighted')\n",
    "    #output.write(str(accuracy) + ',' + str(macro_avg_f1) + ',' + str(weighted_avg_f1))\n",
    "    output.write('{:.2f},{:.2f},{:.2f}\\n'.format(accuracy, macro_avg_f1, weighted_avg_f1))\n",
    "\n",
    "    # Close output file\n",
    "    output.close()\n",
    "\n",
    "def load_dataset(filename, nb_pixels=32**2):\n",
    "    '''\n",
    "    Function for loading the X and Y data of the passed csv file\n",
    "\n",
    "    filename: name of the file containing the dataset (ex: train_1)\n",
    "\n",
    "    Return: \n",
    "    X: 2D numpy array containing the value of the features of each instance\n",
    "    Y: 1D numpy array containing the true class of each instance \n",
    "    '''\n",
    "    data = np.loadtxt('Assig1-Dataset/' + filename + '.csv', delimiter=',', dtype=np.int32)\n",
    "    return data[:, :nb_pixels], data[:, nb_pixels]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Load training and validation data for dataset 1\n",
    "ds1_labels = np.loadtxt('Assig1-Dataset/info_1.csv', skiprows=1, usecols=1, delimiter=',', dtype=np.str)\n",
    "\n",
    "ds1_training_X, ds1_training_Y = load_dataset('train_1')\n",
    "ds1_val_X, ds1_val_Y = load_dataset('val_1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train Base DT model for dataset 1\n",
    "ds1_base_dt_model = sklearn.tree.DecisionTreeClassifier(criterion='entropy').fit(ds1_training_X, ds1_training_Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[8 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0]\n",
      " [0 1 0 1 1 1 0 0 0 1 0 0 0 0 0 0 0 0 1 1 0 0 0 0 0 2]\n",
      " [0 0 8 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 1 0 0 0 0 0 0]\n",
      " [0 0 0 3 0 0 0 0 0 2 0 1 0 0 0 0 0 0 0 1 1 0 0 0 0 0]\n",
      " [0 0 0 0 3 1 0 0 0 0 0 1 0 0 1 0 1 0 0 0 0 0 0 0 0 1]\n",
      " [0 0 0 0 0 3 0 0 0 0 2 0 0 0 0 0 0 0 0 2 0 0 0 0 0 1]\n",
      " [1 0 1 0 0 0 4 0 0 0 0 1 0 0 0 0 0 0 2 0 1 0 0 0 0 0]\n",
      " [1 0 0 0 0 0 0 4 1 1 1 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0]\n",
      " [1 0 0 1 0 0 0 0 5 1 0 0 0 0 0 0 0 1 0 0 0 1 0 0 0 0]\n",
      " [0 0 0 1 2 0 0 0 0 2 0 1 0 0 1 0 1 1 0 1 0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0 0 0 0 0 7 0 0 0 0 0 0 0 0 0 1 0 0 1 1 0]\n",
      " [0 0 0 0 0 0 0 0 0 0 0 7 0 1 0 0 0 0 0 0 1 1 0 0 0 0]\n",
      " [0 0 0 0 0 0 0 0 1 0 1 0 6 0 0 0 0 0 0 0 0 0 0 1 0 1]\n",
      " [0 0 0 0 0 0 0 1 0 0 1 0 0 3 0 0 0 0 0 0 0 1 1 1 1 1]\n",
      " [0 0 1 1 1 0 2 0 0 0 0 0 0 0 2 0 1 0 1 0 1 0 0 0 0 0]\n",
      " [0 1 0 0 0 0 0 0 2 0 0 0 0 0 1 4 0 1 0 1 0 0 0 0 0 0]\n",
      " [0 0 1 0 0 0 1 0 0 0 0 0 0 1 2 0 4 0 0 1 0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 3 1 3 1 0 0 0 0 0 0 2]\n",
      " [0 0 1 0 1 0 4 0 0 0 0 0 0 0 0 0 0 0 3 0 0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0 0 0 0 2 0 0 0 0 0 0 0 0 1 5 0 0 0 0 0 0]\n",
      " [0 1 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 6 0 0 0 0 0]\n",
      " [0 0 0 0 0 0 0 0 0 0 1 0 0 2 0 0 0 0 0 0 0 1 2 1 0 1]\n",
      " [1 0 0 0 0 0 0 0 0 0 1 0 1 0 0 0 0 0 0 0 0 0 5 1 0 0]\n",
      " [1 0 0 0 0 0 0 0 0 0 0 0 0 2 0 0 0 0 0 0 0 0 1 3 0 1]\n",
      " [1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 2 0 0 5 0]\n",
      " [0 0 1 0 0 2 0 0 0 3 0 1 0 0 1 0 0 0 0 0 0 0 0 0 0 1]]\n",
      "\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           A       0.57      0.80      0.67        10\n",
      "           B       0.33      0.11      0.17         9\n",
      "           C       0.62      0.80      0.70        10\n",
      "           D       0.43      0.38      0.40         8\n",
      "           E       0.38      0.38      0.38         8\n",
      "           F       0.38      0.38      0.38         8\n",
      "           G       0.36      0.40      0.38        10\n",
      "           H       0.80      0.44      0.57         9\n",
      "           I       0.56      0.50      0.53        10\n",
      "           J       0.17      0.20      0.18        10\n",
      "           K       0.50      0.70      0.58        10\n",
      "           L       0.58      0.70      0.64        10\n",
      "           M       0.75      0.60      0.67        10\n",
      "           N       0.30      0.30      0.30        10\n",
      "           O       0.25      0.20      0.22        10\n",
      "           P       0.57      0.40      0.47        10\n",
      "           Q       0.50      0.40      0.44        10\n",
      "           R       0.50      0.30      0.37        10\n",
      "           S       0.30      0.33      0.32         9\n",
      "           T       0.38      0.62      0.48         8\n",
      "           U       0.50      0.75      0.60         8\n",
      "           V       0.17      0.12      0.14         8\n",
      "           W       0.56      0.56      0.56         9\n",
      "           X       0.38      0.38      0.38         8\n",
      "           Y       0.71      0.62      0.67         8\n",
      "           Z       0.09      0.11      0.10         9\n",
      "\n",
      "    accuracy                           0.44       239\n",
      "   macro avg       0.45      0.44      0.43       239\n",
      "weighted avg       0.45      0.44      0.44       239\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Use validation data to test first\n",
    "ds1_val_Y_predict = ds1_base_dt_model.predict(ds1_val_X)\n",
    "\n",
    "# Check validation metrics and modify hyper-parameters as needed in previous cell\n",
    "print (sklearn.metrics.confusion_matrix(ds1_val_Y, ds1_val_Y_predict)) # confusion matrix\n",
    "print ('\\n')\n",
    "print (sklearn.metrics.classification_report(ds1_val_Y, ds1_val_Y_predict, target_names=ds1_labels)) # precision, recall, f1-measure (macro and weighted) and accuracy\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[3 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      " [0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0]\n",
      " [0 0 3 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0]\n",
      " [0 1 0 1 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0]\n",
      " [0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1]\n",
      " [0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0]\n",
      " [1 0 1 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 1 0 0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0 0 1 0 0 0 0 1 0 0 0 0 0 0 0 0 0 1 0 0 0]\n",
      " [0 0 0 1 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0]\n",
      " [0 0 0 0 0 0 0 0 1 3 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 1 0 0 0 1 0]\n",
      " [0 0 0 0 0 0 0 0 0 0 0 3 0 0 0 0 0 0 0 0 1 0 0 0 0 0]\n",
      " [0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 2 0]\n",
      " [0 0 0 0 0 0 0 0 0 0 0 0 1 2 0 0 0 0 0 0 0 1 0 0 0 0]\n",
      " [0 0 0 0 0 0 1 0 0 0 0 0 0 0 2 0 0 0 0 0 0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 1 1 0 0 0 0 0 0 0 0 0]\n",
      " [0 0 0 1 0 0 0 0 0 0 0 0 0 0 1 0 1 0 0 0 0 0 0 0 0 0]\n",
      " [0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 2 0 1 0 0 0 0 0 0]\n",
      " [0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 2 0 0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 1 0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 3 0 0 0 0 0]\n",
      " [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 2 1 0 0 0]\n",
      " [1 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 1 0 0 0]\n",
      " [0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0]\n",
      " [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 2 0]\n",
      " [0 0 0 0 0 0 0 0 0 1 0 0 0 1 0 0 0 0 0 0 0 0 0 1 0 0]]\n",
      "\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           A       0.60      0.75      0.67         4\n",
      "           B       0.00      0.00      0.00         2\n",
      "           C       0.75      0.75      0.75         4\n",
      "           D       0.25      0.33      0.29         3\n",
      "           E       0.50      0.50      0.50         2\n",
      "           F       0.50      0.50      0.50         2\n",
      "           G       0.00      0.00      0.00         4\n",
      "           H       1.00      0.33      0.50         3\n",
      "           I       0.50      0.33      0.40         3\n",
      "           J       0.60      0.75      0.67         4\n",
      "           K       0.00      0.00      0.00         3\n",
      "           L       1.00      0.75      0.86         4\n",
      "           M       0.00      0.00      0.00         3\n",
      "           N       0.40      0.50      0.44         4\n",
      "           O       0.40      0.67      0.50         3\n",
      "           P       0.33      0.33      0.33         3\n",
      "           Q       0.50      0.33      0.40         3\n",
      "           R       0.67      0.50      0.57         4\n",
      "           S       0.67      0.67      0.67         3\n",
      "           T       0.33      0.50      0.40         2\n",
      "           U       0.50      1.00      0.67         3\n",
      "           V       0.67      0.67      0.67         3\n",
      "           W       0.33      0.33      0.33         3\n",
      "           X       0.33      0.50      0.40         2\n",
      "           Y       0.40      0.67      0.50         3\n",
      "           Z       0.00      0.00      0.00         3\n",
      "\n",
      "    accuracy                           0.46        80\n",
      "   macro avg       0.43      0.45      0.42        80\n",
      "weighted avg       0.45      0.46      0.44        80\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# When ready, do testing\n",
    "ds1_test_X, ds1_test_Y = load_dataset('test_with_label_1')\n",
    "\n",
    "ds1_test_Y_predict = ds1_base_dt_model.predict(ds1_test_X)\n",
    "\n",
    "# Check test metrics\n",
    "print (sklearn.metrics.confusion_matrix(ds1_test_Y, ds1_test_Y_predict)) # confusion matrix\n",
    "print ('\\n')\n",
    "print (sklearn.metrics.classification_report(ds1_test_Y, ds1_test_Y_predict, target_names=ds1_labels)) # precision, recall, f1-measure (macro and weighted average) and accuracy\n",
    "\n",
    "# Write test results to output file Base-DT-DS1.csv\n",
    "create_output_file(ds1_test_Y, ds1_test_Y_predict, ds1_labels, 'Base-DT-DS1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load training and validation data for dataset 2\n",
    "ds2_labels = np.loadtxt('Assig1-Dataset/info_2.csv', skiprows=1, usecols=1, delimiter=',', dtype=np.str)\n",
    "\n",
    "ds2_training_X, ds2_training_Y = load_dataset('train_2')\n",
    "ds2_val_X, ds2_val_Y = load_dataset('val_2')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train Base DT model for dataset 2\n",
    "ds2_base_dt_model = sklearn.tree.DecisionTreeClassifier(criterion=\"entropy\").fit(ds2_training_X, ds2_training_Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[125   7   3   2  13   2   3   2   1   7]\n",
      " [  9 334   0  19   2   4   2   2   1   2]\n",
      " [  2   3  26   0   2   3   0   0   4   5]\n",
      " [  2  14   1  21   1   3   1   1   0   1]\n",
      " [ 11   6   1   1  84  12   3   1   6  25]\n",
      " [  4   3   5   3   6 122   1   0   1  20]\n",
      " [  0   0   0   0   5   0  34   0   1   5]\n",
      " [  1   1   0   0   1   2   2  38   0   0]\n",
      " [  3   2   3   2   7   1   4   0 117  11]\n",
      " [  5   2  12   0  28  33   5   0   8 282]]\n",
      "\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          pi       0.77      0.76      0.76       165\n",
      "       alpha       0.90      0.89      0.89       375\n",
      "        beta       0.51      0.58      0.54        45\n",
      "       sigma       0.44      0.47      0.45        45\n",
      "       gamma       0.56      0.56      0.56       150\n",
      "       delta       0.67      0.74      0.70       165\n",
      "      lambda       0.62      0.76      0.68        45\n",
      "       omega       0.86      0.84      0.85        45\n",
      "          mu       0.84      0.78      0.81       150\n",
      "          xi       0.79      0.75      0.77       375\n",
      "\n",
      "    accuracy                           0.76      1560\n",
      "   macro avg       0.70      0.71      0.70      1560\n",
      "weighted avg       0.76      0.76      0.76      1560\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Use validation data to test first\n",
    "ds2_val_Y_predict = ds2_base_dt_model.predict(ds2_val_X)\n",
    "\n",
    "# Check validation metrics and adjust hyper-parameters as needed in previous cell\n",
    "print (sklearn.metrics.confusion_matrix(ds2_val_Y, ds2_val_Y_predict)) # confusion matrix\n",
    "print ('\\n')\n",
    "print (sklearn.metrics.classification_report(ds2_val_Y, ds2_val_Y_predict, target_names=ds2_labels)) # precision, recall, f1-measure (macro and weighted) and accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 47   0   1   0   5   0   1   0   0   1]\n",
      " [  0 117   0   3   0   2   1   0   2   0]\n",
      " [  1   0   7   0   0   1   0   0   3   3]\n",
      " [  0   3   0   9   1   2   0   0   0   0]\n",
      " [  4   4   0   1  25   3   0   0   1  12]\n",
      " [  0   0   0   0   4  44   1   0   0   6]\n",
      " [  1   0   2   0   1   1   7   0   2   1]\n",
      " [  0   2   0   0   0   0   0  12   1   0]\n",
      " [  2   1   0   1   1   0   0   0  43   2]\n",
      " [  2   1   2   0  10   9   0   0   2  99]]\n",
      "\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          pi       0.82      0.85      0.84        55\n",
      "       alpha       0.91      0.94      0.92       125\n",
      "        beta       0.58      0.47      0.52        15\n",
      "       sigma       0.64      0.60      0.62        15\n",
      "       gamma       0.53      0.50      0.52        50\n",
      "       delta       0.71      0.80      0.75        55\n",
      "      lambda       0.70      0.47      0.56        15\n",
      "       omega       1.00      0.80      0.89        15\n",
      "          mu       0.80      0.86      0.83        50\n",
      "          xi       0.80      0.79      0.80       125\n",
      "\n",
      "    accuracy                           0.79       520\n",
      "   macro avg       0.75      0.71      0.72       520\n",
      "weighted avg       0.79      0.79      0.79       520\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# When ready, do testing\n",
    "ds2_test_X, ds2_test_Y = load_dataset('test_with_label_2')\n",
    "\n",
    "ds2_test_Y_predict = ds2_base_dt_model.predict(ds2_test_X)\n",
    "\n",
    "# Check test metrics\n",
    "print (sklearn.metrics.confusion_matrix(ds2_test_Y, ds2_test_Y_predict)) # confusion matrix\n",
    "print ('\\n')\n",
    "print (sklearn.metrics.classification_report(ds2_test_Y, ds2_test_Y_predict, target_names=ds2_labels)) # precision, recall, f1-measure (macro and weighted average) and accuracy\n",
    "\n",
    "# Write test results to output file Base-DT-DS2.csv\n",
    "create_output_file(ds2_test_Y, ds2_test_Y_predict, ds2_labels, 'Base-DT-DS2')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
