{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import sklearn\n",
    "from sklearn.neural_network import MLPClassifier as mlp\n",
    "import sklearn.metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define useful functions\n",
    "def create_output_file(y_actual, y_predicted, labels, filename):\n",
    "    '''\n",
    "    Function for creating the ouput file as specified in the assignment instructions:\n",
    "    a) instance number and predicted label (number)\n",
    "    b) Confusion matrix\n",
    "    c) Precision, recall and f1-measure of each class\n",
    "    d) Accuracy, macro-average f1 and weighted-average f1 score of the model\n",
    "\n",
    "    y_actual: numpy array of shape (N,) containing the actual class of each test instance\n",
    "    y_predicted: numpy array of shape (N,) containing the class of each test instance predicted by the model\n",
    "    labels: 1D numpy array containing the class labels of the dataset\n",
    "    filename: name of the output (.csv) file\n",
    "    '''\n",
    "\n",
    "    # Open file\n",
    "    output = open('A1-Output/' + filename + '.csv', 'w')\n",
    "\n",
    "    # a) Write y values of test data\n",
    "    output.write('instance,prediction\\n')\n",
    "    for i in range(y_predicted.shape[0]):\n",
    "        output.write(str(i+1) + ',' + str(y_predicted[i]) + '\\n')\n",
    "\n",
    "    output.write('\\n')\n",
    "\n",
    "    # b) Plot confusion matrix\n",
    "    output.write('confusion matrix\\n')\n",
    "    confusion_matrix = sklearn.metrics.confusion_matrix(y_actual, y_predicted)\n",
    "    (m, n) = confusion_matrix.shape\n",
    "    for i in range(m):\n",
    "        for j in range(n):\n",
    "            if j < n-1:\n",
    "                output.write(str(confusion_matrix[i,j]) + ',')\n",
    "            else:\n",
    "                output.write(str(confusion_matrix[i,j]))\n",
    "        output.write('\\n')\n",
    "\n",
    "    output.write('\\n')\n",
    "\n",
    "    # c) Write precision, recall and f1-measure of each class (rounded to 2 decimals)\n",
    "    output.write('precision,recall,f1-measure\\n')\n",
    "    precision = sklearn.metrics.precision_score(y_actual, y_predicted, average=None)\n",
    "    recall = sklearn.metrics.recall_score(y_actual, y_predicted, average=None)\n",
    "    f1 = sklearn.metrics.f1_score(y_actual, y_predicted, average=None)\n",
    "\n",
    "    for i in range(labels.shape[0]):\n",
    "        #output.write(str(precision[i]) + ',' + str(recall[i]) + ',' + str(f1[i]) + '\\n')\n",
    "        output.write('{:.2f},{:.2f},{:.2f}\\n'.format(precision[i], recall[i], f1[i]))\n",
    "\n",
    "    output.write('\\n')\n",
    "\n",
    "    # Write accuracy, macro-average f1 and weighted-average f1 of the model (rounded to 2 decimals)\n",
    "    output.write('accuracy,macro-average f-1,weighted-average f1\\n') \n",
    "    accuracy = sklearn.metrics.accuracy_score(y_actual, y_predicted)\n",
    "    macro_avg_f1 = sklearn.metrics.f1_score(y_actual, y_predicted, average='macro')\n",
    "    weighted_avg_f1 = sklearn.metrics.f1_score(y_actual, y_predicted, average='weighted')\n",
    "    #output.write(str(accuracy) + ',' + str(macro_avg_f1) + ',' + str(weighted_avg_f1))\n",
    "    output.write('{:.2f},{:.2f},{:.2f}\\n'.format(accuracy, macro_avg_f1, weighted_avg_f1))\n",
    "\n",
    "    # Close output file\n",
    "    output.close()\n",
    "\n",
    "def load_dataset(filename, nb_pixels=32**2):\n",
    "    '''\n",
    "    Function for loading the X and Y data of the passed csv file\n",
    "\n",
    "    filename: name of the file containing the dataset (ex: train_1)\n",
    "\n",
    "    Return: \n",
    "    X: 2D numpy array containing the value of the features of each instance\n",
    "    Y: 1D numpy array containing the true class of each instance \n",
    "    '''\n",
    "    data = np.loadtxt('Assig1-Dataset/' + filename + '.csv', delimiter=',', dtype=np.int32)\n",
    "    return data[:, :nb_pixels], data[:, nb_pixels]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Loading training and validation data for both datasets\n",
    "#dataset 1\n",
    "ds1_labels = np.loadtxt('Assig1-Dataset/info_1.csv', skiprows=1, usecols=1, delimiter=',', dtype=np.str)\n",
    "\n",
    "ds1_training_X, ds1_training_Y = load_dataset('train_1')\n",
    "ds1_val_X, ds1_val_Y = load_dataset('val_1')\n",
    "\n",
    "#dataset 2\n",
    "ds2_labels = np.loadtxt('Assig1-Dataset/info_2.csv', skiprows=1, usecols=1, delimiter=',', dtype=np.str)\n",
    "\n",
    "ds2_training_X, ds2_training_Y = load_dataset('train_2')\n",
    "ds2_val_X, ds2_val_Y = load_dataset('val_2')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Training Base-MLP models\n",
    "baseMLP_ds1 = mlp(activation='logistic',solver='sgd', max_iter=4000).fit(ds1_training_X,ds1_training_Y)\n",
    "baseMLP_ds2 = mlp(activation='logistic',solver='sgd', max_iter=4000).fit(ds2_training_X,ds2_training_Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 9  0  0  0  0  0  0  0  0  0  0  0  0  1  0  0  0  0  0  0  0  0  0  0\n",
      "   0  0]\n",
      " [ 0  6  0  0  0  1  0  0  0  1  0  0  0  0  0  0  0  1  0  0  0  0  0  0\n",
      "   0  0]\n",
      " [ 0  0 10  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n",
      "   0  0]\n",
      " [ 0  1  0  6  0  0  0  0  0  0  0  0  0  0  1  0  0  0  0  0  0  0  0  0\n",
      "   0  0]\n",
      " [ 0  0  0  0  6  1  0  0  0  0  0  1  0  0  0  0  0  0  0  0  0  0  0  0\n",
      "   0  0]\n",
      " [ 0  0  0  0  0  7  0  0  0  0  0  0  0  0  0  1  0  0  0  0  0  0  0  0\n",
      "   0  0]\n",
      " [ 0  0  0  0  0  0  8  0  0  0  0  0  0  0  1  0  1  0  0  0  0  0  0  0\n",
      "   0  0]\n",
      " [ 0  0  0  0  0  0  0  6  0  0  0  0  0  0  0  1  0  0  0  0  0  1  1  0\n",
      "   0  0]\n",
      " [ 0  0  0  0  0  0  0  0 10  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n",
      "   0  0]\n",
      " [ 1  0  0  0  0  0  0  0  0  8  0  0  0  0  0  0  0  0  0  1  0  0  0  0\n",
      "   0  0]\n",
      " [ 0  0  0  0  0  0  0  0  0  0 10  0  0  0  0  0  0  0  0  0  0  0  0  0\n",
      "   0  0]\n",
      " [ 0  0  0  0  0  0  0  0  0  0  0  9  1  0  0  0  0  0  0  0  0  0  0  0\n",
      "   0  0]\n",
      " [ 0  0  0  0  0  0  0  0  0  0  0  0  9  0  0  0  0  0  0  0  0  1  0  0\n",
      "   0  0]\n",
      " [ 1  0  0  0  0  0  0  1  0  0  0  0  0  7  0  0  0  0  0  0  0  1  0  0\n",
      "   0  0]\n",
      " [ 0  0  0  0  0  0  1  0  0  0  0  0  0  0  9  0  0  0  0  0  0  0  0  0\n",
      "   0  0]\n",
      " [ 0  0  0  0  0  0  0  0  0  0  0  0  0  0  0 10  0  0  0  0  0  0  0  0\n",
      "   0  0]\n",
      " [ 0  0  0  0  0  0  1  0  0  0  0  0  0  0  0  0  9  0  0  0  0  0  0  0\n",
      "   0  0]\n",
      " [ 0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  9  0  0  0  0  0  1\n",
      "   0  0]\n",
      " [ 0  0  0  0  0  0  0  0  0  1  0  1  0  0  0  0  0  0  7  0  0  0  0  0\n",
      "   0  0]\n",
      " [ 0  0  0  0  0  1  0  0  0  0  0  0  0  0  0  1  0  0  0  6  0  0  0  0\n",
      "   0  0]\n",
      " [ 0  0  0  0  0  0  0  0  0  0  0  1  0  0  0  0  0  0  0  0  7  0  0  0\n",
      "   0  0]\n",
      " [ 0  0  0  0  0  0  0  0  0  0  0  0  0  4  0  0  0  0  0  0  0  4  0  0\n",
      "   0  0]\n",
      " [ 0  0  0  0  0  0  0  1  0  0  0  0  0  0  0  0  0  0  0  0  0  0  8  0\n",
      "   0  0]\n",
      " [ 1  0  0  0  0  0  0  0  0  0  1  0  0  0  0  0  0  0  0  0  0  1  0  5\n",
      "   0  0]\n",
      " [ 0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n",
      "   8  0]\n",
      " [ 0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n",
      "   0  9]]\n",
      "\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           A       0.75      0.90      0.82        10\n",
      "           B       0.86      0.67      0.75         9\n",
      "           C       1.00      1.00      1.00        10\n",
      "           D       1.00      0.75      0.86         8\n",
      "           E       1.00      0.75      0.86         8\n",
      "           F       0.70      0.88      0.78         8\n",
      "           G       0.80      0.80      0.80        10\n",
      "           H       0.75      0.67      0.71         9\n",
      "           I       1.00      1.00      1.00        10\n",
      "           J       0.80      0.80      0.80        10\n",
      "           K       0.91      1.00      0.95        10\n",
      "           L       0.75      0.90      0.82        10\n",
      "           M       0.90      0.90      0.90        10\n",
      "           N       0.58      0.70      0.64        10\n",
      "           O       0.82      0.90      0.86        10\n",
      "           P       0.77      1.00      0.87        10\n",
      "           Q       0.90      0.90      0.90        10\n",
      "           R       0.90      0.90      0.90        10\n",
      "           S       1.00      0.78      0.88         9\n",
      "           T       0.86      0.75      0.80         8\n",
      "           U       1.00      0.88      0.93         8\n",
      "           V       0.50      0.50      0.50         8\n",
      "           W       0.89      0.89      0.89         9\n",
      "           X       0.83      0.62      0.71         8\n",
      "           Y       1.00      1.00      1.00         8\n",
      "           Z       1.00      1.00      1.00         9\n",
      "\n",
      "    accuracy                           0.85       239\n",
      "   macro avg       0.86      0.84      0.84       239\n",
      "weighted avg       0.86      0.85      0.85       239\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Training model for dataset 1\n",
    "ds1_val_Y_predict = baseMLP_ds1.predict(ds1_val_X)\n",
    "\n",
    "print (sklearn.metrics.confusion_matrix(ds1_val_Y, ds1_val_Y_predict))\n",
    "print ('\\n')\n",
    "print (sklearn.metrics.classification_report(ds1_val_Y, ds1_val_Y_predict, target_names=ds1_labels)) # precision, recall, f1-measure (macro and weighted) and accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[150   0   0   0   6   0   0   0   6   3]\n",
      " [  4 367   1   0   1   1   1   0   0   0]\n",
      " [  1   0  29   1   2   2   0   0   8   2]\n",
      " [  1   2   0  38   2   1   0   0   1   0]\n",
      " [  8   0   1   0 119   5   1   0   1  15]\n",
      " [  0   4   0   2   2 151   0   0   1   5]\n",
      " [  0   3   0   0   0   0  41   0   1   0]\n",
      " [  1   0   0   0   0   2   0  41   0   1]\n",
      " [  3   5   1   0   5   0   0   0 134   2]\n",
      " [  2   3   2   0   8   9   3   0   5 343]]\n",
      "\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          pi       0.88      0.91      0.90       165\n",
      "       alpha       0.96      0.98      0.97       375\n",
      "        beta       0.85      0.64      0.73        45\n",
      "       sigma       0.93      0.84      0.88        45\n",
      "       gamma       0.82      0.79      0.81       150\n",
      "       delta       0.88      0.92      0.90       165\n",
      "      lambda       0.89      0.91      0.90        45\n",
      "       omega       1.00      0.91      0.95        45\n",
      "          mu       0.85      0.89      0.87       150\n",
      "          xi       0.92      0.91      0.92       375\n",
      "\n",
      "    accuracy                           0.91      1560\n",
      "   macro avg       0.90      0.87      0.88      1560\n",
      "weighted avg       0.91      0.91      0.90      1560\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Training model for dataset 2\n",
    "ds2_val_Y_predict = baseMLP_ds2.predict(ds2_val_X)\n",
    "\n",
    "print (sklearn.metrics.confusion_matrix(ds2_val_Y, ds2_val_Y_predict))\n",
    "print ('\\n')\n",
    "print (sklearn.metrics.classification_report(ds2_val_Y, ds2_val_Y_predict, target_names=ds2_labels)) # precision, recall, f1-measure (macro and weighted) and accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DATASET 1\n",
      "\n",
      "[[4 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      " [0 2 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      " [0 0 4 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      " [0 0 0 3 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      " [0 0 0 0 2 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      " [0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0 4 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0 0 3 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0 0 0 3 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0 0 0 1 2 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0 0 1 0 0 2 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0 0 0 0 0 0 4 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0 1 1 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0 0 0 0 0 0 0 1 3 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0 0 0 0 0 0 0 0 0 3 0 0 0 0 0 0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 3 0 0 0 0 0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 3 0 0 0 0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 3 0 0 0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 2 0 0 0 0 0 0 0]\n",
      " [0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 3 0 0 0 0 0]\n",
      " [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 3 0 0 0 0]\n",
      " [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 3 0 0 0]\n",
      " [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 2 0 0]\n",
      " [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 3 0]\n",
      " [0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 2]]\n",
      "\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           A       1.00      1.00      1.00         4\n",
      "           B       1.00      1.00      1.00         2\n",
      "           C       1.00      1.00      1.00         4\n",
      "           D       1.00      1.00      1.00         3\n",
      "           E       1.00      1.00      1.00         2\n",
      "           F       0.50      0.50      0.50         2\n",
      "           G       0.67      1.00      0.80         4\n",
      "           H       0.60      1.00      0.75         3\n",
      "           I       0.75      1.00      0.86         3\n",
      "           J       1.00      0.50      0.67         4\n",
      "           K       0.50      0.67      0.57         3\n",
      "           L       1.00      1.00      1.00         4\n",
      "           M       0.50      0.33      0.40         3\n",
      "           N       1.00      0.75      0.86         4\n",
      "           O       1.00      1.00      1.00         3\n",
      "           P       0.75      1.00      0.86         3\n",
      "           Q       1.00      1.00      1.00         3\n",
      "           R       1.00      0.75      0.86         4\n",
      "           S       1.00      0.67      0.80         3\n",
      "           T       0.50      0.50      0.50         2\n",
      "           U       1.00      1.00      1.00         3\n",
      "           V       1.00      1.00      1.00         3\n",
      "           W       1.00      1.00      1.00         3\n",
      "           X       1.00      1.00      1.00         2\n",
      "           Y       1.00      1.00      1.00         3\n",
      "           Z       1.00      0.67      0.80         3\n",
      "\n",
      "    accuracy                           0.86        80\n",
      "   macro avg       0.88      0.86      0.85        80\n",
      "weighted avg       0.89      0.86      0.86        80\n",
      "\n",
      "\n",
      "=====================================================\n",
      "\n",
      "DATASET 2\n",
      "\n",
      "[[ 51   0   0   1   0   1   0   0   1   1]\n",
      " [  1 121   1   1   0   0   0   0   1   0]\n",
      " [  0   0   9   0   0   1   0   0   4   1]\n",
      " [  1   0   0  14   0   0   0   0   0   0]\n",
      " [  4   1   0   0  36   3   0   0   3   3]\n",
      " [  0   0   1   0   0  52   0   0   0   2]\n",
      " [  0   2   1   0   0   0  11   0   1   0]\n",
      " [  0   0   0   0   0   0   0  15   0   0]\n",
      " [  0   1   1   0   0   0   0   0  47   1]\n",
      " [  2   0   2   0   6   7   0   0   4 104]]\n",
      "\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          pi       0.86      0.93      0.89        55\n",
      "       alpha       0.97      0.97      0.97       125\n",
      "        beta       0.60      0.60      0.60        15\n",
      "       sigma       0.88      0.93      0.90        15\n",
      "       gamma       0.86      0.72      0.78        50\n",
      "       delta       0.81      0.95      0.87        55\n",
      "      lambda       1.00      0.73      0.85        15\n",
      "       omega       1.00      1.00      1.00        15\n",
      "          mu       0.77      0.94      0.85        50\n",
      "          xi       0.93      0.83      0.88       125\n",
      "\n",
      "    accuracy                           0.88       520\n",
      "   macro avg       0.87      0.86      0.86       520\n",
      "weighted avg       0.89      0.88      0.88       520\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Testing for dataset 1\n",
    "ds1_test_X, ds1_test_Y = load_dataset('test_with_label_1')\n",
    "ds1_test_Y_predict = baseMLP_ds1.predict(ds1_test_X)\n",
    "\n",
    "print(\"DATASET 1\\n\")\n",
    "print (sklearn.metrics.confusion_matrix(ds1_test_Y, ds1_test_Y_predict)) # confusion matrix\n",
    "print ('\\n')\n",
    "print (sklearn.metrics.classification_report(ds1_test_Y, ds1_test_Y_predict, target_names=ds1_labels)) # precision, recall, f1-measure (macro and weighted average) and accuracy\n",
    "\n",
    "#Testing for dataset 2\n",
    "ds2_test_X, ds2_test_Y = load_dataset('test_with_label_2')\n",
    "ds2_test_Y_predict = baseMLP_ds2.predict(ds2_test_X)\n",
    "\n",
    "print(\"\\n=====================================================\\n\")\n",
    "print(\"DATASET 2\\n\")\n",
    "print (sklearn.metrics.confusion_matrix(ds2_test_Y, ds2_test_Y_predict)) # confusion matrix\n",
    "print ('\\n')\n",
    "print (sklearn.metrics.classification_report(ds2_test_Y, ds2_test_Y_predict, target_names=ds2_labels)) # precision, recall, f1-measure (macro and weighted average) and accuracy\n",
    "\n",
    "\n",
    "\n",
    "# Write test results to output file GNB-DS1.csv\n",
    "create_output_file(ds1_test_Y, ds1_test_Y_predict, ds1_labels, 'Base-MLP-DS1')\n",
    "create_output_file(ds2_test_Y, ds2_test_Y_predict, ds2_labels, 'Base-MLP-DS2')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
